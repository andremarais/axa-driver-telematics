% THIS IS AN EXAMPLE DOCUMENT FOR VLDB 2012

\documentclass{vldb}
\usepackage{graphicx}
\usepackage{balance}  % for  \balance command ON LAST PAGE  (only there!)
\usepackage{fixltx2e}
\usepackage{verbatim}
\usepackage{hyperref}
\begin{document}

% ****************** TITLE ****************************************

%\title{A Sample {\ttlit Proceedings of the VLDB Endowment} Paper in LaTeX
%Format\titlenote{for use with vldb.cls}}
\title{Unsupervised Anomaly Detection using \ttlit{H2O.ai}}


% possible, but not really needed or used for PVLDB:
%\subtitle{[Extended Abstract]
%\titlenote{A full version of this paper is available as\textit{Author's Guide to Preparing ACM SIG Proceedings Using \LaTeX$2_\epsilon$\ and BibTeX} at \texttt{www.acm.org/eaddress.htm}}}

% ****************** AUTHORS **************************************

\numberofauthors{2} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.

\author{
% 1st. author
\alignauthor
Peter Schrott\\
       \affaddr{Berlin Institute of Technology}\\
       \email{peter.schrott@campus.tu-berlin.de}
% 2nd. author
\alignauthor
Julian Voelkel\\
       \affaddr{Berlin Institute of Technology}\\
       \email{voelkel@campus.tu-berlin.de}  
}
\date{15 July 2015}

\maketitle

%\pagebreak

%\begin{abstract}
%The abstract for your paper for the PVLDB Journal submission.
%The template and the example document are based on the ACM SIG Proceedings  templates. This file is part of a package for preparing the submissions for review. These files are in the camera-ready format, but they do not contain the full copyright note.
%Note that after the notification of acceptance, there will be an updated style file for the camera-ready submission containing the copyright note.
%\end{abstract}

%Term Report Structure
%1 . Cover Page: Title, Authors, Author Email Adresses, Course Title, Date
%2. Introduction
	%Anomaly Detection
	% Deeplearning Auto Encoder
%3. Problem Statement
	% Discover if Deep Learning Auto-Encoder is well suited for anomaly detection on an unlabeled dataset
%4. Methodology
	%(How are we trying to answer the question)
	% Apply implementation of said algorithm on dataset that has been worked on by x-thousand people
	% description dataset
%5. Experiments
	%(Description of experiments performed in order to be able to answer the question as to whether or not a 	%deep learning auto encoder is well suited for anomaly detection in an unsupervised environment)
%6. Results
	%(Did our experiments yield results that help answer the question)
%7. Conclusion
	%(Conclusion based on experiments and results of the experiments, structure of dataset, feature extraction)
%8. References

\section{Introduction}
\textit{Anomaly detection} (commonly referred to as \textit{outlier detection}) is one of a few very common tasks in the field of Machine Learning. The goal of algorithms designed for the purpose of anomaly detection, are concerned with finding data in a dataset that does not conform to a pattern. That means, the goal is to identify data points, that are special in regards to their behavior, compared to the data points in the dataset, that are considered "normal". \cite{survey:anomaly-detection} These data points are called outliers, because they show different behavior than one would expect. Figure \ref{fig:outlier-basic} shows a basic plot containing data points, with two different populations, along with two outliers, that do not seem to fit either pattern.\\
\begin{figure}
\centering
\includegraphics[scale=0.5]{"pics/outlier_basic"}%width=\textwidth
\caption{ADD SOME DESCRIPTIVE CAPTION HERE... }
\label{fig:outlier-basic}
\end{figure}
The value of identifying outliers in a dataset lies in the action one can take after detecting them. Two common applications of anomaly detection algorithms are health care and fraud detection. In the former, those algorithms can for instance help identifying sick patients, by identifying anomalous vital signs compared in a group of similar patients. In the latter application, those algorithms can account for fast, actionable information in case of credit card fraud, which can be identified by anomalous purchases, given the owners purchase pattern in form of historical purchases. \\
Anomaly detection can happen in a supervised, semi-supervised, as well as in an unsupervised fashion. The credit card fraud detection would be a semi-supervised learning task, since we can assume, that a new credit card will not be the subject of fraud for at least the first couple of purchases. Hence, we obtain a training set of "normal" purchases (i.e. data point) and can for each newly generated data point decide, whether it conforms to the pattern or does not. Since our project is focused exclusively on the unsupervised case where we do not know which data points are considered normal, but rather have to find a structure or pattern in the data first, in order to then be able to identify data points not conforming to the pattern, the next section will focus on unsupervised anomaly detection.
%Difference to binary classification? -> Only data of one class given
%simple plot
%\subsection{Supervised Learning}
\subsection{Challenges of Unsupervised Anomaly Detection}
One difficulty that arises in unsupervised anomaly detection is, since we do not have any labels for training data, we do not even know what we are looking for. That is, we do not know what a "normal" data point would like, let alone what an anomalous point would look like. To put it in Ted Dunning and Ellen Friedman's words: "Anomaly detection is about finding what you don't know to look for." \cite{book:mapr} 
Since there is no labeled training data in the most widely applicable case of unsupervised anomaly detection, the approach of finding outliers is a different one compared to training a model and then predicting to which class an unseen data point belongs to (much like binary classification). Instead, in case of unsupervised anomaly detection, we generally assume that the number of "normal" data points exceeds the number of anomalous data points by far.\cite{survey:anomaly-detection}. This assumption is fundamental to unsupervised outlier detection, since we would not be able to learn what is normal otherwise. Not being able to determine what "normal" is, means there is no way of finding what is anomalous. Since the goal of anomaly detection is finding what is anomalous, unsupervised anomaly detection usually starts with figuring out what "normal" is. After achieving this (which, oftentimes, is much harder than it sounds), we can determine the deviation of a data point to what is "normal" using some similarity measure. There are, however, different algorithms dealing with the problem of unsupervised anomaly detection for different fields and problem domains. The main reason why there is no single approach applicable to each problem is, that there are tremendous differences in what is considered normal and what is considered anomalous, depending on the application domain we are looking at. Considering an example for this circumstance given in \cite{survey:anomaly-detection}, one can easily imagine why that is the case: "The exact notion of an anomaly is different for different application domains. For example, in the medical domain a small deviation from normal (e.g., fluctuations in body temperature) might be an anomaly, while similar deviation in the stock market domain (e.g., fluctuations in the value of a stock) might be considered as normal. Thus applying a technique developed in one domain to another is not straightforward."\\
%TODO common techniques/algorithms used in unsupervised anomaly detection

\subsection{Deep Learning Auto-Encoder}


?

\section{Problem Statement} \label{problem_statement}
%with Target and Scope
%The \textit{proceedings} are the records of a conference.
Anomaly detection refers to the task of identifying observations, that do not match the pattern of the data. Oftentimes anomaly detection happens in an unsupervised context. That is, the dataset being operated on is unlabeled, and the goal is to identify exactly those samples, that fit the pattern of the dataset the least. In this project, we shall analyze the performance of a particular algorithm in the field of unsupervised anomaly detection. Specifically, with this project, we aim at providing an answer or at least hints to the answer of the question: \textbf{Is a Deep Learning Auto-Encoder\footnote{An artificial neural network used for efficient codings.} 
well suited for anomaly detection in an unlabeled dataset?}
\subsection{Target}\label{target}
As stated above, target of this project is to evaluate the quality of a Deep Learning Auto-Encoder model for the task of identifying anomalies in an unsupervised context. 
\subsection{Scope}\label{ssec:scope}
This project consists of various different steps in order to obtain an answer to the problem specified above.
These steps can be outlined as follows:
\begin{enumerate}
	\item Study an existing implementation of the Deep Learning Auto-Encoder model
	\item Apply this implementation to a given unlabeled dataset
	\item Compare the outcome to already existing outcomes of other algorithms
	\item Draw conclusions about the general suitability of the algorithm based on the results of the application of its implementation
\end{enumerate}

%\section{Problem Statement}
\section{Methodology}
\section{Experiments}
\section{Results}
\section{Conclusion}
\section{References}

\section{Project Plan}\label{projcet_plan}
%As specified in \ref{ssec:scope}, there are four different steps to be made in order to obtain an answer %to the original problem statement. These steps are 
In order to being able reach our goal specified in \textbf{\ref{problem_statement}. \nameref{problem_statement}}, we need the following things:
 \begin{enumerate}
 	\item An implementation of the Deep Learning Auto-Encoder model
 	\item A dataset, and
	\item Reference results
\end{enumerate}
%\subsection{Objectives}\label{objectives}
%The main objective of this project is to evaluate the suitability of a Deep Learning Auto-Encoder model %for identifying anomalies. 
\subsection{Methodology, Objectives and Experiments}\label{planned_methodology}

In this project, we use \textit{H2O.ai}'s\footnote{An open source parallel processing engine for machine learning} implementation of the Deep Learning Auto-Encoder model through its Scala API on top of Apache spark. The dataset we use in order to being able to compare our results to those of our peers is the \textit{AXA Driver Telematics Analysis} dataset\footnote{This dataset was released to the public as a competition on \url{https://www.kaggle.com/}. It can be found here: \url{https://www.kaggle.com/c/axa-driver-telematics-analysis/data?drivers.zip}}, which contains multiple vehicle traces by multiple drivers. The catch with this dataset is that while there is a folder for each driver with a number of his or her respective traces, there is always a varying and unknown number of traces that were being generated by other drivers in that particular folder as well. \\
Since this dataset does not contain labels for the data, uploading our results to Kaggle, allows us to obtain a performance evaluation and being able to compare our results to other people's results, yielded from other algorithms. 
%\cite{bowman:reasoning}
	




% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{vldb_sample}  % vldb_sample.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references

%\subsection{References}
%Generated by bibtex from your ~.bib file.  Run latex,
%then bibtex, then latex twice (to resolve references).

%APPENDIX is optional.
% ****************** APPENDIX **************************************
% Example of an appendix; typically would start on a new page
%pagebreak




\end{document}
