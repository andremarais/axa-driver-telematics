% THIS IS AN EXAMPLE DOCUMENT FOR VLDB 2012

\documentclass{vldb}
\usepackage{graphicx}
\usepackage{balance}  % for  \balance command ON LAST PAGE  (only there!)
\usepackage{fixltx2e}
\usepackage{verbatim}
\usepackage{hyperref}
\usepackage{subcaption}
\usepackage{lipsum}
\usepackage{gensymb}

% ****************** TITLE ****************************************

\title{Unsupervised Anomaly Detection using \ttlit{H2O.ai}}
\subtitle{AIM-3 - Scalable Data Analysis and Data Mining}


% ****************** AUTHORS **************************************

\numberofauthors{2} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.

\author{
% 1st. author
\alignauthor
Peter Schrott\\
       \affaddr{Berlin Institute of Technology}\\
       \email{peter.schrott@campus.tu-berlin.de}
% 2nd. author
\alignauthor
Julian Voelkel\\
       \affaddr{Berlin Institute of Technology}\\
       \email{voelkel@campus.tu-berlin.de}  
}

\date{}

\begin{document}

\maketitle

\begin{abstract}
In the era of Big Data and scalable data analytics, we observe a rapidly developing space of both supervised and unsupervised algorithms for various different purposes within the domain of machine learning. Incremental progress in some spaces and rebirth along with signficant improvements for whole families of algorithms like neural networks mark the last few years of research in this area. Those constant improvements of algorithms together with the ubiquity of digital sensors and thus data, allow for application of algorithms in the real world yielding valuable insights for the respective user of those algorithms. Remarkable progress has been made in particular, in the family of deep learning algorithms for different kinds of applications, primarily though, in image recognition as well as natural language processing.\\
In this work, we investigate the performance of a specific algorithm from the family of deep learning, originally designed for a different purpose, in the domain of unsupervised anomaly detection. Throughout this investigation, we try to provide insights into the usability as well as the suitabiliy of the algorithm for this problem domain, by applying an existing implementation oft the algorithm to a publicly available dataset.
\end{abstract}

%Term Report Structure
%1 . Cover Page: Title, Authors, Author Email Adresses, Course Title, Date
%2. Introduction
	%Anomaly Detection
	% Deeplearning Auto Encoder
%3. Problem Statement
	% Discover if Deep Learning Auto-Encoder is well suited for anomaly detection on an unlabeled dataset
%4. Methodology
	%(How are we trying to answer the question)
	% Apply implementation of said algorithm on dataset that has been worked on by x-thousand people
	% description dataset
%5. Experiments
	%(Description of experiments performed in order to be able to answer the question as to whether or not a 	%deep learning auto encoder is well suited for anomaly detection in an unsupervised environment)
%6. Results
	%(Did our experiments yield results that help answer the question)
%7. Conclusion
	%(Conclusion based on experiments and results of the experiments, structure of dataset, feature extraction)
%8. References

%-------------------- INTRODUCTION ---------------------------------------------------------

\section{Introduction}
\label{sec:Introduction}

\begin{figure}
\centering
\includegraphics[width=\linewidth]{"pics/outlier_basic"}
\caption{Sample of two populations a two outliers.}
\label{fig:outlier-basic}
\end{figure}

\textit{Anomaly detection} (commonly referred to as \textit{outlier detection}) is one of a few hot topics in the field of Machine Learning. The goal of algorithms designed for the purpose of anomaly detection are concerned with finding data in a dataset that does not conform to a pattern. That means, the goal is to identify data points, that are special in regards to their behavior, compared to the data points in the dataset, that are considered "normal". \cite{survey:anomaly-detection} These data points are called outliers, because they show different behavior than one would expect. Figure \ref{fig:outlier-basic} shows a basic plot containing data points, with two different populations, along with two outliers, that do not seem to fit either pattern.\\
The value of identifying outliers in a dataset lies in the action one can take after detecting them. Common applications of anomaly detection algorithms include among others health care and fraud detection. In the former, those algorithms can for instance help identifying sick patients, by identifying anomalous vital signs compared in a group of similar patients. In the latter application, those algorithms can account for fast, actionable information in case of credit card fraud, which can be identified by anomalous purchases, given the owners purchase pattern in form of historical purchases. \\
Anomaly detection can happen in a supervised, semi-super\-vised, as well as in an unsupervised fashion. The credit card fraud detection would be a semi-supervised learning task, since we can assume, that a new credit card will not be the subject of fraud for at least the first couple of purchases. Hence, we obtain a training set of "normal" purchases (i.e. data point) and can for each newly generated data point decide, whether it conforms to the pattern or does not. Since our project is focused exclusively on the unsupervised case where we do not know which data points are considered normal, but rather have to find a structure or pattern in the data first, in order to then be able to identify data points not conforming to the pattern, the next section will focus on unsupervised anomaly detection and the challenges we face in its context.


\subsection{Challenges of Unsupervised Anomaly Detection}
\label{subsec:Intro-challenges}

\begin{figure}
\begin{subfigure}{\linewidth}
	\centering
	\includegraphics[width=.8\linewidth]{"pics/ekg"}
	\caption{Obvious outlier in small sample size ...}
	\label{subfig:context-a}
\end{subfigure}
\begin{subfigure}{\linewidth}
  \centering
  \includegraphics[width=.8\linewidth]{"pics/ekg2"}
  \caption{... are not necessarily outliers in the context of the whole dataset}
  \label{subfig:context-b}
\end{subfigure}
\caption{Contextual anomaly}
\label{fig:contextual-anomaly}
\end{figure}

One difficulty that arises in unsupervised anomaly detection is, since we do not have any labels for training data, we do not even know what we are looking for. That is, we do not know what a "normal" data point would look like, let alone what an anomalous point would look like. To put it in Ted Dunning's and Ellen Friedman's words: "Anomaly detection is about finding what you don't know to look for." \cite{book:mapr} 
Since there is no labeled training data in the most widely applicable case of unsupervised anomaly detection, the approach of finding outliers is a different one compared to training a model and then predicting to which class an unseen data point belongs to (much like binary classification). Instead, in case of unsupervised anomaly detection, we generally assume that the number of "normal" data points exceeds the number of anomalous data points by far.\cite{survey:anomaly-detection} This assumption is fundamental to unsupervised outlier detection, since we would not be able to learn what is normal otherwise, as a relatively large number of anomalous points would change the skew the structure of the data in a way, that would make determining what is "normal" impossible . Not being able to determine what "normal" is, means there is no way of finding what is anomalous. Since the goal of anomaly detection is finding what is anomalous, unsupervised anomaly detection usually starts with figuring out what "normal" is. After achieving this (which, oftentimes, is much harder than it sounds), we can determine the deviation of a data point to what is "normal" using some similarity measure. There are, however, different algorithms dealing with the problem of unsupervised anomaly detection for different fields and problem domains. The main reason why there is no single approach applicable to each problem is, that there are tremendous differences in what is considered normal and what is considered anomalous, depending on the application domain we are looking at. Considering an example for this circumstance given in \cite{survey:anomaly-detection}, one can easily imagine why that is the case: "The exact notion of an anomaly is different for different application domains. For example, in the medical domain a small deviation from normal (e.g., fluctuations in body temperature) might be an anomaly, while similar deviation in the stock market domain (e.g., fluctuations in the value of a stock) might be considered as normal. Thus applying a technique developed in one domain to another is not straightforward." Besides the domain specificity of anomalies, there is also the context specificity of anomalies to keep in mind. This concept is illustrated in Figure \ref{fig:contextual-anomaly}, taken from \cite{book:mapr} \\
Common techniques and algorithms used to perform unsupervised anomaly detection include clustering based methods, statistical techniques, information theoretic methods as well as spectral techniques. Note, however, that the choice of algorithm can depend heavily on the problem's domain.


\subsection{Deep Learning Auto-Encoder}
\label{subsec:Intro-deep}

\begin{figure}
\centering
\includegraphics[width=0.8\linewidth]{"pics/auto-encoder"}
\caption{Schematic diagram of a basic auto-encoder with three input features}
\label{fig:auto-encoder}
\end{figure}

An auto-encoder, autoassociator or Diablo network is a specific type of artificial neural network. The goal of a deep learning auto-encoder is to learn a compressed encoding of a dataset. Due to that purpose, the auto-encoder consists of one input layer, one or more hidden layers and an output layer with equally as many neurons (i.e. features) as the input layer.  In order to achieve the goal of representing a dataset in a compressed manner, the auto-encoder is given the original dataset as input, while the target output is the input itself. \cite{rep:u-montreal} The loss function is some type of dissimilarity function (typically a squared error function) between the input and the output of the auto-encoder. This way, the auto-encoder is forced to learn a nonlinear (or linear), compressed representation of the original dataset. This, of course, makes the auto-encoder a useful tool for dimensionality reduction. For the special case where there is only one linear hidden layer with $k$ neurons and the mean squared error criterion is used to train the auto-encoder, the hidden layer consisting of the $k$ neurons learns to represent the dataset in the dimension of its first $k$ principal components. \cite{rep:u-montreal} This is much like Principal Component Analysis (PCA). If, however, the hidden layer is of nonlinear nature, then the auto-encoder behaves very different compared to PCA. \cite{article:nonlinear-autoassociator}.
Due to its ability to learn a compressed version of the dataset, the main application of the deep learning auto-encoder is obviously dimensionality reduction. In our case, though, we want to use the deep learning auto-encoder in order to perform unsupervised anomaly detection. \\
A schematic diagram of an auto-encoder taken from \cite{article:astronomy} is given in Figure \ref{fig:auto-encoder}. 

%Schematic diagram of an autoencoder. The three input values are encoded to two feature variables. Pre-training (described in Section 3.3) defines the weight matrices W1 and W2.


\section{Problem Statement} \label{problem_statement}
%with Target and Scope
%The \textit{proceedings} are the records of a conference.
As already mentioned in \textbf{\ref{sec:Introduction}. \nameref{sec:Introduction}}, anomaly detection refers to the task of identifying observations, that do not match the general pattern of the dataset they arise in. Oftentimes anomaly detection happens in an unsupervised context, which means that the dataset being operated on is unlabeled, and the goal is to identify exactly those samples, that fit the pattern of the dataset the least. This is also the case we want to investigate regarding the usability of a certain algorithm originally designed for a different purpose. Within the scope of this project, we analyze the performance of a particular algorithm more commonly used in a field different to the one of unsupervised anomaly detection. Specifically, with this project, we aim at providing an answer or at least hints to the answer of the question: \textbf{Is a deep learning auto-encoder} (see Section \ref{subsec:Intro-deep}) \textbf{well suited for anomaly detection in an unlabeled dataset?}


\subsection{Target}\label{target}
As stated above, target of this project is to evaluate the quality of a deep learning auto-encoder model for the task of identifying anomalies in an unsupervised context. Experiments comparing the performance of the deep learning auto-encoder with the performance of other algorithms in the same context shall indicate whether it is a good idea to use the auto-encoder in the context of unsupervised anomaly detection or not.


\subsection{Scope}\label{ssec:scope}
This project consists of various different steps in order to obtain an answer to the problem specified above.
These steps can be outlined as follows:
\begin{enumerate}
	\item Study an existing implementation of the deep learning auto-encoder model
	\item Apply this implementation to a given unlabeled dataset
	\item Compare the outcome to already existing outcomes of other algorithms
	\item Draw conclusions about the general suitability of the algorithm based on the results produced by the application of its implementation compared to those of other algorithms
\end{enumerate}


%-------------------- METHODOLOGY ---------------------------------------------------------

\section{Methodology}
Within the scope of this project, we use H2O.ai's (see section \ref{subsec:Metho-h2o}) implementation of the deep learning auto-encoder model through its Sparkling Water API on top of Apache Spark. The dataset we use in order to be able to compare our results to those of our peers using different algorithms is the AXA Driver Telematics Analysis dataset (see \ref{subsec:Metho-dataset}), which contains multiple trips by multiple drivers.

%The catch with this dataset is that while there is a folder for each driver with a number of his or her respective traces, there is always a varying and unknown number of traces that were being generated by other drivers in that particular folder as well. \\
%Since this dataset does not contain labels for the data, uploading our results to Kaggle, allows us to obtain a performance evaluation and being able to compare our results to other people's results, yielded from other algorithms. 
%(How are we trying to answer the question)
% Apply implementation of said algorithm on dataset that has been worked on by x-thousand people
% description dataset


\subsection{H2O.ai  and H2O Deep Learning}
\label{subsec:Metho-h2o}

\begin{figure}
\begin{subfigure}{\linewidth}
	\centering
	\includegraphics[width=\linewidth]{"pics/outlier_basic"}
	\caption{The given unlabeled dataset...}
	\label{subfig:reduction-a}
\end{subfigure}
\begin{subfigure}{\linewidth}
  \centering
  \includegraphics[width=.76\linewidth]{"pics/reduced-rep"}
  \caption{...is reduced in dimensionality...}
  \label{subfig:reduction-b}
\end{subfigure}
\begin{subfigure}{\linewidth}
  \centering
  \includegraphics[width=.9\linewidth]{"pics/reconstruction"}
  \caption{...and reconstructed, in order to find outliers}
  \label{subfig:reduction-c}
\end{subfigure}
\caption{Identifying outliers by reconstruction error}
\label{fig:auto-encoder-reconstruction}
\end{figure}

H2O by H2O.ai is an open source software project primarily used for fast scalable in-memory machine learning. The product strongly aims for data scientists who work in a distributed manner. The software offers a predictive analytics platform, combining high performance parallel processing with an extensive machine learning library. \cite{website:h2o} H2O was built on top of Apache Hadoop as well as Apache Spark. As of February 2015, the software has more than 12,000 users and is deployed by more than 2,000 companies, including PayPal, Nielsen and Cisco. \cite{booklet:deep-learning}\\

H2O is shipped with its own distributed in-memory data store which is integrated as an key-value store on top of non-blocking hash maps. The basic type for datasets in H2O is the H2OFrame. An H2OFrame consists of vectors, where each vector represents one column, respectively one feature. As opposed to the H2OFrame, the vectors are immutable. The access to the data is granted by an evaluation layer build with R. This layer also builds the bridge to the REST interface. For the computation part the base is build by basic operations as fork, join, map and reduce. These are used by the H2O prediction engine. All algorithm, either provided by H2O or custom implemented, use that engine to build their individual model. The data storage and data analysis takes palace in the so called H2O cloud which runs on one or more nodes. For each node a Java Virtual Machine is instanciated and run the above described operations. The H2O cloud is accessible through network by interfaces for Python, R, Java, Scala, Tabelau/Excel or the H2O WebUI. \\

Besides Distributed Random Forests, K-means, Generalized Linear Model and Gradient Boosting Machine, H2O also offers readily available deep learning algorithms, which includes the auto-encoder. \\
As mentioned in section \ref{subsec:Intro-deep}, the deep learning auto-encoder is an algorithm that is used primarily for dimensionality reduction. The way we want to use the auto-encoder to detect outliers in an unsupervised manner is shown in figure \ref{fig:auto-encoder-reconstruction}. As it can be seen there, the algorithm is forced to learn the identity through a non-linear, reduced representation of original data. This is done by first reducing the data's dimensionality and then reconstructing it from that reduced representation. Since one assumption in unsupervised anomaly detection is that the number of normal data points exceeds the number of anomalous ones by far (see section \ref{subsec:Intro-challenges}), that learned model will be mostly influenced more by what is normal in the data than by what is anomalous. Thus, attempting to reconstruct a data point from its reduced representation will have a greater error than anomalous data points that it will have for normal data points.\\
The H2O version of its deep learning auto-encoder is based on simple map reduce tasks as of that is a fast an memory efficient implementation. It profits from an multi-threaded implementation that allows a distributed parallel computation for deployment on a multi-node cluster. The algorithm uses stochastic gradient descent for the problem of minimizing the loss function. It provides regularisation including L1, L2, dropout and Hogwild!. Also the activation and loss function can be parametrized by the user.


\subsection{The AXA Driver Telematics Analysis \\Dataset}
\label{subsec:Metho-dataset}

\begin{figure}
\centering
\includegraphics[width=\linewidth]{"pics/axa-trip"}
\caption{A visualization of the raw dataset. Each line is generated by connecting the $(x,y)$ coordinates of one particular trip and is thus a visualization of that one particular trip}
\label{fig:axa-trip}
\end{figure}

The AXA Driver Telematics dataset is a dataset that was being released to the public in form of a Kaggle challenge 
\footnote{Find the challenge with the dataset here: \url{https://www.kaggle.com/c/axa-driver-telematics-analysis/data}}
The dataset is a directory based dataset. This means meta data is implicitly contained in the directory and file structure of the dataset. In total there are logs for 2736 drivers. There is one designated folder for each driver, each of which contains 200 different trips in form of CSV files. In the raw data, a single trip is given by a single CSV file consisting of two columns and a varying number of rows. For every single drive, there is one column containing x coordinates one column containing y coordinates. Each row then represents the driver's position one second after the previous row. Every trip has been anonymized, such that each trip starts at position $(x, y) = (0, 0)$ and all the following coordinates have been randomly rotated.\\ 
For instance, the first few rows in the CSV file representing driver one's first trip are shown in table \ref{table:raw-trace}

\begin{table}
\centering
\begin{tabular}{l c r}
x & y\\
0 & 0\\
18.6 & -11.1 \\
36.1 & -21.9 \\
53.7 & -32.6 \\
. & .  \\
. & . \\
. & . \\	
\end{tabular}
\caption{The first few rows of the driver one's first trip}
\label{table:raw-trace}
\end{table}

The catch with this dataset is that while there is a folder for each driver with a number of his or her respective trip, there is always a varying and unknown number of trips that were being generated by other drivers (otherwise not represented in the dataset) in that particular folder as well. These unlabeled outliers is what we hope end up identifying using the deep learning auto-encoder. \\
Figure \ref{fig:axa-trip} (taken from \href{https://www.kaggle.com/c/axa-driver-telematics-analysis/data}{kaggle.com}) shows what the whole dataset might look like, if we just plotted each driving trip as a line connecting its consecutive $(x, y)$ points.\\

With a size of 1.44 GB compressed and 5.92 GB in extracted state, this dataset can be considered reasonably large and thus, processing the dataset on a parallel system is justified. \\
The fact, that AXA, a major car insurance provider (amongst other things), releases a dataset of this kind with the goal of identifying anomalies in driving patterns to the public, hints at a real world application for anomaly detection algorithms that generates value of some kind. In this case, the companies goal might have been to identify or count the times a person not insured for a particular car still drove said car. Identifying those instances might for instance allow challenging of fraudulent insurance claims. Another way AXA might profit from identifying anomalies in drives is, that having an estimate of the numbers of uninsured drives allows for adjustment of internal calculations of revenue, deductions and the like, as well as adjustment of insurance rates. If not one of the above, there has to be some kind of incentive for AXA to be able to identify anomalies. \\
In our case, however, the fact that more than 1,500 teams already submitted their solutions, allows for some benchmarking of the deep learning auto-encoder.


\subsection{Feature Extraction}
\label{subsec:Metho-feature}

\begin{figure}
\centering
\includegraphics[trim=0cm 5.8cm 11.7cm 0cm, clip=true, width=0.8\linewidth]{"pics/approach1"}
\caption{Schematic visualization of our feature extraction}
\label{fig:approach-1}
\end{figure}

In order to be able to find the anomalous driving trips for each driver contained in our dataset by applying the H2O deep learning auto-encoder, we have to extract features from our trips first. Ideally, those feature would be meaningful, with large variance in those driving trips that were generated by other drivers. We use Apache Flink in order to extract our features, as illustrated in Figure \ref{fig:approach-1}. Since every trip is initially given as a CSV file containing only $(x, y)$ coordinates of that trip (see section \ref{subsec:Metho-dataset}), we implement a feature extraction engine that calculates different features for each driving trip.\\
Hence the dataset is not provided in the usual format contributions to the Apache Flink core project are made to create the necessary API for preserving the information given by the folder / file structure. The name of the folder is considered as the driver ID, the filename as trip ID. Furthermore a custom implementation of an Apache Flink conform \textit{InputFormat} has to be programmed. Simply reading the CSV files would destroy the context of the data. The trick is, to not split the files while reading, as it is usually done on a distributed file system like HDFS. The result of the input pipeline are trips labeled by driver ID and trip ID containing a sequence of $(x, y)$ coordinates. Also important is to preserve the sequence of the $(x, y)$ tuples as the chronological order characterizes the route.\\
The mined features include for instance driven distance (see formula (1)), time of the trip, speed (see formula (2)), acceleration (see formula (3)), changes of heading (see formula (4)). For speed and acceleration the mean, median, deviation of the mean of the drivers mean, standard deviation and maximum are added. The change of heading is used to determine the number of significant turns. This are turns bigger than 35\degree, 75\degree and 160\degree within a window of 10 seconds. Additionally a left turn is considered as a negative value, a right turn as a positive. The intention behind the counts is to characterise the drivers routes. Utilized by the delta speed of each entry in a trip, stops can be computed. This is where the speed is 0. Similar to the changes of heading the length of the stops are provided as further features. Stops longer than 1, 3, 10 and 120 seconds are counted. The shorter stops describe stop-and-go traffic. Traffic light stops are between 10 and 120 seconds. Longer stops can be considered as breaks.\\
After extracting all the features, we obtain one feature vector for each trip of each driver. The outcome is materialized as CSV file where the rows represent a trip and the columns a feature. The feature vectors are ultimately pass to the auto-encoder as input vectors, are of fundamental meaning for the quality of the anomaly detection. Depending on their significance for a driver's fingerprint, the algorithm might perform well or it might produce unusable results in case the features do not bear a large significance for a driver's pattern of driving.

\begin{align}
\delta d_i &= \sqrt{(x_{i-1} - x_{i})^2 + (y_{i-1} - y_{i})^2} \\
\delta v_i &= \frac{\delta d}{\delta t} \\
\delta a_i &= \frac{\delta v_{i-1} - \delta v_{i}}{\delta t} \\
\cos \alpha_i &= \frac{\vec{v_1} \cdot \vec{v_2}}{|\vec{v_1}|_2 * |\vec{v_2}|_2}
\end{align}
\begin{align*}
\text{where:}\\
v_1 =& p_{n-1} - p_{n} \\
v_2 =& p_{n} - p_{n+1}\\
\end{align*}


\subsection{Exploratory Data Analysis}
In order to get an overview of the data we are dealing with, we perform exploratory data analysis, mainly in the form of visualizations.

\begin{figure*}
\centering
\includegraphics[width=\linewidth]{"pics/duration-vs-distance-driver"}
\caption{Plot of duration versis distance for each trip by each driver}
\label{fig:duration-vs-distance}
\end{figure*}
Figure \ref{fig:duration-vs-distance} gives a overview of the dataset by displaying the duration and distance of every single trip for a few drivers. What we can see here already, is a rather large variance in trip duration among different drivers. Also, there seem to be cases where the driver did barely move, as well as very short trips (short in the sense of time passed during the trip).

\begin{figure}
\centering
\includegraphics[width= 0.8\linewidth]{"pics/all_drives_18"}%width=\textwidth
\caption{All trips of driver 18 visualized}
\label{fig:driver-18}
\end{figure}
Figure \ref{fig:driver-18} provides some insights about driver 18. Since the plot contains all 200 recorded driving trips of that driver, including the drives not originating from driver 18, we can attempt to see some anomalies here. In this case, we can clearly see, only by looking at the driven distance, that a handful drives do not seem to fit the pattern of  this particular driver, which seems to be to drive rather short distances.\\
Using the above mentioned features we extracted, exploratory data analysis yields some other insights about variation in driving pattern amongst drivers, as well as some anomalous behavior among driving trips for single drivers as well.
 
\begin{figure}
\centering
\includegraphics[width=\linewidth]{"pics/box-plot-distance"}%width=\textwidth
\caption{Boxplot of distances for 20 driver}
\label{fig:box-plot-distance}
\end{figure}
The box plot in Figure \ref{fig:box-plot-distance} for instance shows not only the variation of driving distance among drivers, but also between different trips for one driver.  In particular, this box plot seems to confirm the assumptions made about driver 18's driving pattern after having seen the plot of all that driver's trip in Figure \ref{fig:driver-18}. That is, because we can clearly see in the box plot, that driver 18 has a very low variation when it comes to trip length. 

\begin{figure}
\centering
\includegraphics[width=\linewidth]{"pics/number-of-breaks-10-120"}%width=\textwidth
\caption{Number of stops with 10 - 120 seconds}
\label{fig:number-of-breaks-10-120}
\end{figure}
Considering the number of stops per driver and their respective driving trip is also helpful in detecting driving patterns. In Figure \ref{fig:number-of-breaks-10-120}, size and color of the circle visualize the number of stops between 10 seconds and 120 seconds. The insights we gain from this plot can be the revealing of the area the respective driver commonly drives in. A constant high number of short breaks might indicate a driver mainly driving in urban areas. In this case, trips with more infrequent, shorter stops could be considered anomalous because the might originate from a rural driver.


%-------------------- EXPERIMENTS ---------------------------------------------------------

\section{Experiments}
\label{sec:Experiments}

\begin{figure}
\centering
\includegraphics[trim=0cm 24.2cm 9.2cm 0cm, clip=true, width=\linewidth]{"pics/experiment-plan"}
\caption{Experiment plan}
\label{fig:Exp-plan}
\end{figure}

In order to ensure a structured approach for finding the optimal application of the deep learning auto-encoder on the AXA Driver Telematics datast and the corresponding hyper-parameters, we set up a plan to run the experiments. A simplification of the execution plan can be seen in figure \ref{fig:Exp-plan}. To cover the question, whether the anomalies can only be found among the trips of one driver or even in a more general global context, we build the model in two different ways. First the model is fitted on the entire trainings dataset. In the second and third approach one model for each driver is build. In the third run a recursive implementation is chosen.

\subsection{Experiment 1}
\label{subsec:exp-1}
In experiment 1 a generalized model is build. The idea behind this approach is, that a wide model will cause a certain reconstruction error for each feature vector. Hence the generalization this error will not be minimal, but bigger for anomalies. Our assumption is that the resulting vector of reconstruction errors will represent the probability of an outlying data point. The normalization of the reconstruction error is, as it can be seen in Figure \ref{fig:Exp-plan}. The determination of the probability is considered in a local, as well as a global context. A more detailed description of the computations can be found in section \ref{subsec:sparkling-impl}. 

\subsection{Experiment 2}
\label{subsec:exp-2}

The second approach aims at overcoming this generalization by assembling trips of one driver to build the trainings set for the deep learner auto-encoder. In a first step a unique set of driver IDs is created. After that, iterative model fitting and scoring is done driver by driver. To avoid over-fitting a higher L2-regularisation is applied. The figures can be seen in Table \ref{table:param-set-exp2}. The final result is build as a union of the individual result sets. The normalization is performed as explained in experiment 1.

\subsection{Experiment 3}
\label{subsec:exp-3}
The idea of experiment 3 lays in the result of the initial two experiments (see section \ref{ssubsec:Res-e1} and \ref{ssubsec:Res-e2}) and the qualitative evaluation as described in section \ref{subsec:Quali-eval}. Low results on Kaggle.com leave open questions about the quantity of the model. However plots show, that the model is capable of finding outliers at least outliers in a visual respect. For experiment 3 the assumption is made, that extreme outliers influence the model fitting in a negative manner. To prove the truth of this assumption we use a recursive model fitting approach. After fitting a model for each driver on the entire dataset the two trips with the highest reconstruction error are removed from the dataset. The filtered dataset is fed back into the model building process. This method helps to prevent a strongly biased model fitting on outlying data points. The parameter set is left unchanged to experiment 2. Hence the trips with the biggest reconstruction error are removed they also will not influence the final computation of the probability as described in formula (5).

\subsection{Sparkling Implementation}
\label{subsec:sparkling-impl}

\begin{figure}
\centering
\includegraphics[trim=0cm 9cm 7.4cm 0cm, clip=true, width=0.8\linewidth]{"pics/approach2"}
\caption{Schematic visualization of experiments}
\label{fig:approach-2}
\end{figure}

As stated in section \ref{subsec:Metho-h2o} the scalable machine learning library of H2O.ai builds the core of the experimental implementation. H2O.ai provides a comprehensive API named Sparkling Water for interfacing the H2O cloud. This API is written in Java and Scala and is usually embedded in a data flow of an Apache Spark application. \\
In the following, the implemented data flow and data transformations are explained. See figure \ref{fig:approach-2} for an overview. The first step is to load the input data from the HDFS on to the cluster. A regular Apache Spark RDD is used as container. The first transformation is to convert the line-wise input string to representative Plain Old Java Objects (POJOs). The POJOs are stored in the Apache Spark context on the nodes of the cluster. This is a very common step within scalable data analysis.\\
Within the next step towards the outlier-detection, the RDD containing the input data is transformed to an Apache Spark DataFrame. A DataFrame is the representation of a rational database table in Spark SQL and stored in its SQL-context. Apache Spark aims at structured data processing and acts as distributed SQL-engine. To transform the data, the schema of the table is to be set and alongside the DataFrame registered in the SQL-context. Once this is done, a SQL query can be used to obtain the data in the format of an H2OFrame. A H2OFrame is analogue to the DataFrame, the representation of datasets within the H2O-context. For the experiments, we fetch all features for every trip as training data.\\
Once the training data is in the right format the model for the deep learning auto-encoder is set up and parametrized. This is done by initiating an instance of the \textit{DeepLearning} class of the Sparkling Water API. The parameters for experiment 1 and experiment 2 are shown in table \ref{table:param-set-exp1} and table \ref{table:param-set-exp2} respectively. This parameter set is chosen based on the evaluation results returned by Kaggle.com. As the model fitting takes place in a unsupervised environment, the response column will be ignored and for that reason set to any non static column. Tangens hyperbolicus provides a bounded activation function for the output forwarding to the next neuron. It is a simple activation function and the symmetry around 0 makes the algorithm converge faster. The number of hidden layers is set to 1 layer with 8 neuron. The number of neurons on the hidden layer is determined by applying Principal Component Analysis (PCA) on the dataset and getting an estimate of the number of principal components that cover most of the variance in the dataset.

\begin{table}
\centering
\begin{tabular}{l | c}
Parameter            & Value\\ \hline
training data        & all available trips (2736 x 200) \\
response column      & any non static column \\
autoencoder          & true \\
activation function  & tanh \\
hidden layers        & 1 \\
Neurons per hidden layer        & \{ 8 \}\\
epochs               & 20\\
L2-normalization     & 0.001
\end{tabular}
\caption{Parameter set for deep learning auto-encoder in experiment 1}
\label{table:param-set-exp1}
\end{table}

\begin{table}
\centering
\begin{tabular}{l | c}
Parameter            & Value\\ \hline
training data        & all trips of current driver (200) \\
response column      & any non static column \\
autoencoder          & true \\
activation function  & tanh \\
hidden layers        & 1 \\
Neurons per hidden layer        & \{ 8 \}\\
epochs               & 20\\
L2-normalization     & 0.2
\end{tabular}
\caption{Parameter set for deep learning auto-encoder in experiment 2s}
\label{table:param-set-exp2}
\end{table}

For the prediction the model provides an interface called \textit{scoreAutoEncoder(..)}, which takes the test data as parameter. As stated in section \ref{subsec:Metho-h2o} in our case the test dataset is equivalent to the training dataset. The result of the prediction is a vector containing the reconstruction error of the features for every trip. As the vectors of an H2OFrame are immutable the resulting reconstruction errors can be joined to the test dataset row by row. This is simply done by adding the error as additional column to the input dataset. Furthermore the columns of the features are deleted as they are not relevant for further evaluations. \\
In the final step the H2OFrame is transformed back into the Spark RDD representation. Back in the Spark context,  a simple map operation is used to  normalize the reconstruction error by using formula (5).

\begin{align}
\hat{x_i} = \frac{x_i - min(X)}{max(X) - min(X)}
\end{align}
After normalizing, the Spark API is used to print the output to a text file. The resulting text file is in the Kaggle format, consisting of 547200 rows containing the probabilities for each driver and trip. In addition to the output for Kaggle a second file is created containing the raw reconstruction error instead of the probability.


%-------------------- RESULTS ---------------------------------------------------------

\section{Results}
\label{sec:Results}

\subsection{Evaluation of the Result}
\label{subsec:eval-result}
In order to be able to obtain indications as to whether the deep learning auto-encoder is suitable for anomaly detection, we have to somehow evaluate its findings. The common approach in data analysis and machine learning for classification is to do k-fold cross-validation method to find the optimal hyper-parameter. This parameter set minimizes the error of the prediction. For this the dataset is at least divided into to random splits, usually 70/30, for training and testing respectively. After fitting the model with the training dataset, predications on the test dataset are made. By comparing the predicted result and the true labels the error is calculated. This error represents the quality of the model.\\
In a unsupervised learning environment such a optimization strategy is not possible, due to the absence of labels for the dataset. One measurement is the reconstruction error for anomaly detection by dimensionality reduction. As stated in section \ref{subsec:Metho-dataset}, the dataset was the subject of a Kaggle.com challenge.For the scope of our problem statement we luckily can use the evaluation of the prediction on the website.  Our prediction of outliers will automatically be graded after uploading it. The website will give us the accuracy of our predication as value of the area under the ROC curve. The Kaggle submissions format is outlined in table \ref{table:kaggle-submission}. Every row represents a trip, labeled by driver ID and trip ID, along with a probability whether said trip actually belongs to the driver or not. Value 1 indicates the highest probability, 0 the lowest. \\
As a second method towards quality evaluation a visual approach was chosen. The trips with the $n$ biggest reconstruction error are filtered from the original dataset. In a second step the $m$ biggest outliers of each driver found in step one is collected. This method provides a decent amount of result for visual evaluation. Utilized by python and matplot-lib the trips and outliers are plotted. For our experiments we filter 15 trips with the biggest reconstruction error and highlight the first most significant outliers for each unique driver among the filtered trips. \\
 
\begin{table}
\centering
\begin{tabular}{l c}
driver\_trip, & prob\\
1\_1,& 1\\
1\_2,& 1\\
1\_3,& 1\\
1\_4,& 0\\
... & ... \\
... & ... \\
\end{tabular}
\caption{Submission format for Kaggle.com}
\label{table:kaggle-submission}
\end{table}


\subsection{Kaggle Results}

As stated in Section \ref{subsec:eval-result}, we upload the predictions obtained from our implementation to Kaggle.com, where they are being evaluated. 

\subsubsection*{Result of Experiment 1}
\label{ssubsec:Res-e1}

\begin{figure}
\centering
\includegraphics[width=\linewidth]{"pics/kaggle-result-1"}
\caption{Scoring on Kaggle.com's leaderboard for experiment 1}
\label{fig:kaggle-result1}
\end{figure}

The score on Kaggle.com for experiment 1 was quite low. We achieved a ROC score of 0.53014 as can be seen in Figure \ref{fig:kaggle-result1}. This score is only slightly better than randomly guessing or labeling every trip with the highest probability. What this experiment also showed is, that the result is invariant towards changes in normalization, activation function, loss function as well as the methodology of building the deep learning auto-encoder model. Also, the different approaches for computation of the probability does not significantly change the score.

Explanations for this result are among others:
\begin{itemize}
\item Too high degree of generalization of the model
\item Wide variances between individual drivers
\item Lack of cross-validation for optimizing the hyper-pa\-ra\-me\-ter
\end{itemize}

\subsubsection*{Result of Experiment 2}
\label{ssubsec:Res-e2}

\begin{figure}
\centering
\includegraphics[width=\linewidth]{"pics/kaggle-result-2"}
\caption{Scoring on Kaggle.com's leaderboard for experiment 2}
\label{fig:kaggle-result2}
\end{figure}

Driven by the sobering low results of experiment 1 and the resulting change of model fitting strategy increased the score on Kaggle.com by almost 20\%. As shown in Figure \ref{fig:kaggle-result2} the score reached 61.897\% of a prediction accuracy. This result confirms the assumption drawn in experiment 2. We claimed a less general fitting approach will result in a better detection of anomalies. As the result shows, the variance among the drivers is overcome and the individual outliers are found more reliably.

The mid-range quality of this result can be explained by the following reasons:
\begin{itemize}
\item Noisy data can influence the fitting of the model
\item Lack of cross-validation for optimizing the hyper-pa\-ra\-me\-ter
\end{itemize}

\subsubsection*{Result of Experiment 3}
\label{ssubsec:Res-e3}

\begin{figure}
\centering
\includegraphics[width=\linewidth]{"pics/kaggle-result-3"}
\caption{Scoring on Kaggle.com's leaderboard for experiment 3}
\label{fig:kaggle-result3}
\end{figure}
 
Experiment 3 for a more stable model towards \textit{learning what's normal} once again resulted in an improvement of accuracy, thus yielding a higher score on Kaggle.com. Removing the two trips with the highest reconstruction error improves the prediction result as can be seen on the rating of an area under the ROC curve value of 0.6239. The result is shown in figure \ref{fig:kaggle-result3}. 

\subsection{Qualitative Evaluation}
\label{subsec:Quali-eval}

For the qualitative evaluation, the drivers having trips with especially high reconstruction errors are filtered from the original dataset. For each unique driver out of the filtered data, all trips are plotted. Those trips with the by far highest reconstruction error are then marked red. \\
Manually evaluating those chosen trips (without true labels of course) shows some interesting insights, giving more hints as to how the poor accuracy of predictions came to be, as opposed to the value of the area under the ROC curve given by Kaggle.com, which does not allow for more assumptions. \\

In Subfigure \ref{subfig:d-1634-junk}  it can clearly be seen, that the driving trip with the highest reconstruction error is a false recording or junk drive, as all the other trips can barely be seen (small fuzz in the top left corner). This becomes even more obvious after removing said junk drive from the plot with the goal of being able to see the structure of the other drives, as illustrated in Subfigure \ref{subfig:d-1634}. This figure reveals the true structure of the nonjunk drives of driver 1634. The same pattern can be seen in Figure \ref{fig:d-1635}. The unintuitively edgy and straight looking lines can clearly be classified as data noise from an objective point of view. Those specific trips are clearly not more than junk data resulting from poor GPS recordings. Apparently, only jumps in locations are recorded, even outside of the boundary of a usual trip distance as Subfigure \ref{subfig:d-1634-junk} shows in a clear manner. For other drivers, not containing obvious junk drives, the model seems to successfully identify (judging by eye) anomalous driving trips. This can be seen in Figure \ref{fig:d-3506}\\
The conclusions that can be drawn from the qualitative evaluation is, that the model was successfully trained to find outliers. Unfortunately, our feature extraction does not account for all data noise and junk drives, which might cause problems in two ways. First of all, the model (or what is considered normal) will additionally to the influence of the outliers be influenced by the data noise. Secondly, resulting confidence scores that a data point is anomalous are of course higher for junk trips, because those are - in a way - anomalous. The computation of the outlier probabilities, based on the reconstruction error, possibly causes the suboptimal result on Kaggle.com. Observing formula (5) shows, that if the maximum of the reconstruction error is far off from the other values, the range of the probabilities is distorted. That is, a junk drive that becomes a extraordinarily high confidence score of being anomalous, causes the other drives to have a in relation to that score really low score. Computing the outlier probabilities then results in having a really high number of trips with a probability of being normal close to 99 \%, while only the few junk drives have a low probability of being considered normal. This can also be seen by analyzing the files, uploaded to Kaggle.com.

\begin{figure}
\centering
\includegraphics[width=0.8\linewidth]{"pics/outliers_junk/D_3506"}
\caption{All trips of driver 3506. Trips with the highest reconstruction error are marked in red}
\label{fig:d-3506}
\end{figure}


%-------------------- CONCLUSION ---------------------------------------------------------

\section{Conclusion}
\label{sec:Conclusion}

The aim of our project was to provide evidence to the question as to whether the deep learning auto-encoder is suitable for anomaly detection in an unsupervised environment. Applying an existing parallel implementation of the algorithm from a software house with a particularly strong reputation - namely H2O.ai - should enable us to provide evidence to the answer to the before mentioned question to at least some extent. Since evaluating unsupervised learning algorithms is a particularly tough task, in particular if the dataset's size has to be big enough to be considered "Big Data", working on a dataset from Kaggle.com, should allow us to let their system take care of the model evaluation part. Additionally, the availability of scores from more than 1,500 other teams using other algorithms would allow us to compare the auto-encoder's performance directly to those of other algorithms.\\
As we describe in Section \ref{sec:Results}, our third and last experiment would have finished 952th out of 1,529 teams by obtaining an area under the ROC curve value of 0.6239. This result is far from being optimal for the use case of anomaly detection. However, it is also significantly better than the random classifier benchmark of 0.5. That being said, taking our inexperience with neural networks and unsupervised anomaly detection into account, one might argue, that an expert in the area or at least a more experienced team might achieve better results using the same algorithm, but in a more experienced design of experiments. Also, paying more attention to the noise contained in the dataset, along with smarter feature extraction might lead to further improvements. Conceptionally, however, we show, that the deep learning auto-encoder is applicable to real world unsupervised anomaly detection, although it is particularly tough to find the right hyper-parameters. \\
For future work we propose applying the algorithm to an already cleaned dataset, with - if possible - already existing features. The fact that unsupervised anomaly detection becomes even harder in the presence of noisy data lets us reach this conclusion. In particular, we propose applying the deep learning auto-encoder to a dataset consisting of digital images, in order to be able to draw more conclusions in regards to its suitability for this domain, without spoiling the results with a poor choice of features or a lot of noise in the data.

\bibliography{vldb_sample}

\newpage

\begin{figure}
\begin{subfigure}{\linewidth}
	\centering
	\includegraphics[width=.8\linewidth]{"pics/outliers_junk/D_1634_with_136"}
	\caption{All trips including junk}
	\label{subfig:d-1634-junk}
\end{subfigure}
\begin{subfigure}{\linewidth}
  \centering
  \includegraphics[width=0.8\linewidth]{"pics/outliers_junk/D_1634_wo_136"}
\caption{Trips without junk drive}
\label{subfig:d-1634}
\end{subfigure}
\caption{All trips of driver 1634}
\label{fig:d-1634}
\end{figure}

\begin{figure}
\begin{subfigure}{\linewidth}
	\centering
	\includegraphics[width=0.8\linewidth]{"pics/outliers_junk/D_1635_unclean"}
	\caption{All trips including junk}
	\label{subfig:d-1635-junk}
\end{subfigure}
\begin{subfigure}{\linewidth}
  \centering
	\includegraphics[width=0.8\linewidth]{"pics/outliers_junk/D_1635_clean"}
	\caption{Trips without junk drive}
	\label{subfig:d-1635}
\end{subfigure}
\caption{Trips of driver 1635}
\label{fig:d-1635}
\end{figure}

\end{document}


